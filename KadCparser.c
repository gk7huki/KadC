/****************************************************************\

Copyright 2004 Enzo Michelangeli

This file is part of the KadC library.

KadC is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
(at your option) any later version.

KadC is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with KadC; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

In addition, closed-source licenses for this software may be granted
by the copyright owner on commercial basis, with conditions negotiated
case by case. Interested parties may contact Enzo Michelangeli at one
of the following e-mail addresses (replace "(at)" with "@"):

 em(at)em.no-ip.com
 em(at)i-t-vision.com

\****************************************************************/

/* #define DEBUG */

#include <pthread.h>
#include <assert.h>
#include <stdio.h>
#include <ctype.h>
#include <string.h>
#include <stdlib.h>
#include <KadCalloc.h>
#include <int128.h>
#include <bufio.h>
#include <opcodes.h>
#include <queue.h>
#include <net.h>
#include <KadCthread.h>
#include <KadCmeta.h>

extern specialxtable sxt[];

typedef enum {
	TOKEN_AND,
	TOKEN_OR,
	TOKEN_AND_NOT,
	TOKEN_NOT,
	TOKEN_GE,
	TOKEN_GT,
	TOKEN_LE,
	TOKEN_LT,
	TOKEN_EQ,
	TOKEN_NE,
	TOKEN_LPAR,
	TOKEN_RPAR,
	TOKEN_STRING,
	TOKEN_EOF,
	TOKEN_ERR,
	/* these are special cases of strings, never generated by the
	   lexical analizer. The first and second pass of the parser
	   change TOKEN_STRING into one of the following as appropriate */
	TOKEN_TAGNAME,	/* a string used as first operand of relops  */
	TOKEN_TAGDWORDNAME,	/* a string expected to be used as first operand of <, <=, >, >=  */
	TOKEN_TAGSTRINGNAME, /* a string expected to be used as first operand of =, != */
	TOKEN_TAGSTRINGVALUE,/* a string used as second operand of relops */
	TOKEN_KEYWORD,	/* a predicate (i.e., a keyword for in searches)  */
	TOKEN_TRUE		/* a zero-length predicate, meaning "true" */
} op_t;

/* Lexical symbols */
typedef struct _token {
	const char *s;	/* string (not necessarily zero-terminated!) */
	op_t op;		/* opcode */
	int length;		/* length of string in s */
	unsigned long limit;	/* used only for relops, to embed operand */
} token;

#include <KadCparser.h>

#define arraysize(s) (sizeof(s)/sizeof(s[0]))
#define MAXFILTERSIZE (4096)	/* enough? */


/* 2-chars operators MUST be listed before 1-char operators sharing
   the first char */
static const token termsym[] = {
/*	"&!" MUST BE REMOVED from source syntax, despite its availability
	in object "instructions set". The associative rules are ugly.
	{"&!", TOKEN_AND_NOT,	2},*/
	{"&&", TOKEN_AND,	2},
	{"&", TOKEN_AND,	1},
	{"||", TOKEN_OR,	2},
	{"|", TOKEN_OR,		1},
	{">=", TOKEN_GE,	2},
	{">", TOKEN_GT,		1},
	{"<=", TOKEN_LE,	2},
	{"<", TOKEN_LT, 	1},
	{"!=", TOKEN_NE,	2},
	{"!", TOKEN_NOT,	1},
	{"==", TOKEN_EQ,	2},
	{"=", TOKEN_EQ,		1},
	{"(", TOKEN_LPAR,	1},
	{")", TOKEN_RPAR,	1}
};

static token make_token(const char *s, op_t op) {
	token t = {0};
	t.s = s;
	t.op = op;
	t.length = strlen(t.s);
	return t;
}

/* KadC_gettoken: (lexical analizer): gets a new token from string
   pointed by *p
   Note: it returns NOT a pointer to a token, but the struct itself
   passed by value, and which doesn't need to be free'd.
 */
token KadC_gettoken(char **p, char *inputend) {
	int i = 0;
	token t = {0};
	token t_err = make_token("[EOF]", TOKEN_EOF);
	int quotesign = 0;
	char *startstring = NULL;
	int stringlen = 0;
	char strterm[arraysize(termsym)+1]  = {0};

	/* first skip any whitespace */

	for(;;) {
		if(*p >= inputend)
			return t_err;
		if(!isspace(**p))
			break;
		(*p)++;
	}

	/* then, check if it's an operator or parenthesis */

	for(i=0; i<arraysize(termsym); i++) {
		int l = termsym[i].length;
		if(*p + l > inputend)
			continue;
		if(strncmp(*p, termsym[i].s, l) == 0) {	/* match? */
			*p += l;
			return termsym[i];
		}
	}
	/* well, it's not an operator. So let's assume it's a string. */
	if(**p == '\'' || **p == '\"') {
		quotesign = *(*p)++;	/* start of a string delimited by either single of double quotes */
	} else {
		quotesign = 0;
		for(i=0; i<arraysize(termsym); i++)
			strterm[i] = termsym[i].s[0];	/* strterm contains initial chars of operators */
	}
	strterm[i+1] = 0;

	startstring = *p;

	for(; ;(*p)++) {
		if(*p >= inputend) {
			if(quotesign)
				return make_token("Unbalanced quotes", TOKEN_ERR);
			else {
				stringlen = *p - startstring;
				break;	/* unquoted strings are ended by input end */
			}
		}
		if(quotesign) {
			/* quoted strings are terminated by matching quotes */
			if(**p == quotesign) {
				quotesign = 0;
				stringlen = *p - startstring;
				(*p)++;	/* skip closing quote sign */
				break;	/* quoted strings are ended by matching quotes */
			}
		} else {
			/* non-quoted strings are terminated by operstors or whitespace or quotes*/
			if(strchr(strterm, **p) != NULL || isspace(**p) ||
				**p == '\'' || **p == '\"') {
				stringlen = *p - startstring;
				break;
			}
		}
	}
	t.s = startstring;
	t.length = stringlen;
	t.op = TOKEN_STRING; /* all other strings are keywords, tagnames or tagvalues */
	return t;
}

/* Recursive descent (to hell) parser for s_filters

	Grammar:

   <expr> 		::= <term> [ OR <term> ]*
   <term>		 ::= <predicate> [ AND predicate ]*
   <predicate>	::= TRUE | <keyw> | <tagname> <relop> <tagvalue> | NOT <predicate> | ( <expr> )
   <relop>  	::= LT | LE | GT | GE | EQ | NE
   <keyw>		::= <string>
   <tagname>	::= <string>
   <tagvalue>	::= <string>

The tokenizer recognizes keywords, TRUE, tagnames and tagvalues as generic
strings. The first pass of the parser changes string tokens into their
appropriate subtypes, so that the second pass will never see TOKEN_STRING
tokens. Moreover, the operators >, >=, < and <= can only take integer
values as second operand. Those strings are treated as decimal, octal
or hex unsigned long constants (with the C language syntax), converted and
appended to the operator token (in the field ".limit"), suppressing the
original string.
The = and != operators should always take string values, but when used
with integer tagnames (SIZE, bitrate, and for others with EDONKEY_MTAG_DWORD
type in the sxt[] table defined in KadCmeta.c) they are expanded on the fly
into combinations of >= and <=. In particular,
  SIZE = 123    ->    SIZE <= 123 & SIZE >= 123
  SIZE != 123   ->   !(SIZE <= 123 & SIZE >= 123)

The parser tries to do the most of the information it has. If the tagname
is not a special listed in sxt[], it relies on the particular operator
to decide whether the tagvalues should be treated as string or as integer.
If the tagname is listed as EDONKEY_MTAG_DWORD, it assumes that the second
operand should be an integer and it reports a parsing error if the conversion
fails. If the tagname is listed as EDONKEY_MTAG_STRING, it reports an error
if a relational operator different from = and != is found, and treats the
tagvalue as a string even if it's a decimal or hex constant. In case of
uncertainty, please build main/KadCparser with "make MAIN=KadCparser",
run it, and experiment. For example, try the following filters:
  a<1
  a<=1
  SIZE>123
  SIZE > abc
  SIZE != 123
or more complicated expressions such as
  xyz = "ab, cd" & (SIZE != 123 | bitrate <= 256) &!FORMAT=mp3

The first pass of parser emits a stream of RPN bytecodes, so we have to push
them onto a stack to reverse them later during the filter code generation
(eDonkey filters are in prefix notation). This is done in the second pass.
The operands are reversed, but that's OK because all the boolops we parse
are symmetric, and eDonkey filters want the operands reversed ("a > 100" ->
"> 100 a"). In the first pass, when we push the intermediate code onto the
stack, we also perform some macro expansions, so to implement
boolops and relops not directly available as "opcodes" in the eDonkey
search filters:

	Orig.infix	   Expanded infix		RPN

	NOT b 		-> .TRUE. AND_NOT b
	a LT b		-> NOT (a GE b) 	->	a GE(b) TRUE AND_NOT
	a GT b		-> NOT (a LE b)		->	a LE(b) TRUE AND_NOT
	a NE b		-> NOT (a EQ b)		->	a EQ b TRUE AND_NOT

*/

typedef struct _parsercontext {
	char *p;			/* pointer to the current position in the input buffer */
	char *pend;			/* points to the end of the input buffer */
	token lookahead;	/* lookahead token */
	token **tstack;		/* token stack */
	int tsp;			/* token stack pointer */
	int tssize;			/* max size of stack */
	parsing_error errcode;
	const char *err1;			/* first part of error message */
	const char *err2;			/* second part of error message */
} parsercontext;

/* pop from the stack the topmost operand (if any) */
static token *unemit(parsercontext *ppc) {
	if(ppc->tsp == 0) {
		return NULL;
	} else {
#ifdef DEBUG
		printf("[<POP!]");
#endif
		ppc->tsp--;
		return ppc->tstack[ppc->tsp];
	}
}

static void emit(parsercontext *ppc, token *pt) {
	/* macro expansions and/or simple optimizations */
	{
		/* component tokens to build s_filter codes missing from eDonkey op tags:
		   relops TOKEN_LE, TOKEN_GE, TOKEN_NE and boolop TOKEN_NOT  */
		token tandnot = {"&!", TOKEN_AND_NOT, 2, 0};	/* in RPN, actually NOT_AND... */
		token teq =     {"=",  TOKEN_EQ,      1, 0};
		token tnot =    {"!",  TOKEN_NOT,     1, 0};
		token ttrue =   {"",   TOKEN_TRUE,    0, 0};
		token t = *pt;
		switch(t.op) {
		case TOKEN_NOT:
			emit(ppc, &ttrue);
			emit(ppc, &tandnot);
			break;
		case TOKEN_LE:
			/* a <= b  ->  a < b+1 */
			if(++t.limit == 0) {
				/* a <= 0xffffffff  ->  .TRUE. */
				free(unemit(ppc));		/* remove tagname */
				emit(ppc, &ttrue);	/* replace it with .TRUE. */
			} else {
				t.op = TOKEN_LT;
				t.s = "<";
				emit(ppc, &t);
			}
			break;
		case TOKEN_GE:
			/* a >= b  ->  a > b-1 */
			if(t.limit == 0) {
				/* a >= 0  ->  .TRUE. */
				free(unemit(ppc));		/* remove tagname */
				emit(ppc, &ttrue);	/* replace it with .TRUE. */
			} else {
				t.limit--;
				t.op = TOKEN_GT;
				t.s = ">";
				emit(ppc, &t);
			}
			break;
		case TOKEN_NE:
			emit(ppc, &teq);
			emit(ppc, &tnot);
			break;
		default:
			goto not_a_macro;
		}
		return;
	}
not_a_macro:


#ifdef DEBUG
	{
		int i;
	/* debugging printout */
		switch(pt->op) {
		case TOKEN_TAGNAME:
		case TOKEN_TAGSTRINGNAME:
		case TOKEN_TAGDWORDNAME:
			if(pt->length == 1) {	/* special? */
				for(i = 0; sxt[i].name != NULL; i++) {
					if(sxt[i].code[0] == pt->s[0]) {
						printf("{%s}", sxt[i].name);
						break;
					}
				}
				if(sxt[i].name != NULL)
					break;
			}	/* else fall through */
		case TOKEN_AND:
		case TOKEN_OR:
		case TOKEN_AND_NOT:
		case TOKEN_EQ:
		case TOKEN_NE:
		case TOKEN_KEYWORD:
		case TOKEN_TAGSTRINGVALUE:
			printf("[");
			for(i=0; i < pt->length; i++)
				printf("%c", pt->s[i]);
			printf("]");
			break;
		case TOKEN_EOF:
			printf("[EOF]");
			break;
		case TOKEN_ERR:
			printf("[ERR: %s]", pt->s);
			break;
		case TOKEN_TRUE:
			printf("[.TRUE.]");
			break;
		case TOKEN_LT:
		case TOKEN_GT:
			printf("[%lu%s]", pt->limit, pt->s);
			break;
		default:
			printf("[UNKNOWN: ");
			for(i=0; i < pt->length; i++)
				printf("%c", pt->s[i]);
			printf("]");
			break;
		}
	}
#endif

	ppc->tstack[ppc->tsp] = malloc(sizeof(token));
	assert(ppc->tstack[ppc->tsp] != 0);
	*ppc->tstack[ppc->tsp] = *pt;	/* push a reference to a copy of the token onto the stack */
	assert(ppc->tsp < ppc->tssize);	/* it must not cause overflow... */
	ppc->tsp++;		/* bump up stack pointer */
}

/* get a token from ppc->p and put it in ppc->lookahead */
static void get_new_token(parsercontext *ppc) {
	ppc->lookahead = KadC_gettoken(&ppc->p, ppc->pend);
#ifdef DEBUG
	{
		int i;
		printf("** Token string: \"");
		for(i=0; i<ppc->lookahead.length; i++)
			printf("%c", ppc->lookahead.s[i]);
		printf("\" op: %d\n", ppc->lookahead.op);
	}
#endif
}

static void parse_error(parsercontext *ppc, int code, const char *s1, const char *s2) {
	ppc->errcode = code;
	ppc->err1 = s1;
	ppc->err2 = s2;
}

/* called on tokens of TOKEN_STRING type, it returns a replacement of
   type TOKEN_TAGSTRINGNAME or TOKEN_TAGDWORDNAME if an entry for that string
   is found in the sxt[] table with type EDONKEY_MTAG_STRING or EDONKEY_MTAG_DWORD;
   the type will remain unchanged if no entry is found, or one with type
   EDONKEY_MTAG_UNKNOWN.
   Also, if an entry for that string is found with code different from
   EDONKEY_STAG_UNKNOWN, the string in the replacement token will be replaced by
   that code.
   If no entry is found, the routine returns a token identical to the original. */
static token specialtagname(token t) {
	int i;
	token t1 = t;	/* clone token first */

	for(i=0; sxt[i].name != NULL; i++) {
		if(strncmp(t.s, sxt[i].name, t.length) == 0) {	/* at the first match: */
			if(sxt[i].code[0] != EDONKEY_STAG_UNKNOWN) {
				t1.s = sxt[i].code;
				t1.length = 1;
			}
			if(sxt[i].type == EDONKEY_MTAG_STRING)
				t1.op = TOKEN_TAGSTRINGNAME;
			else if(sxt[i].type == EDONKEY_MTAG_DWORD)
				t1.op = TOKEN_TAGDWORDNAME;
			break;
		}
	}
	return t1;
}

static void expr(parsercontext *ppc);

static void predicate(parsercontext *ppc) {
	token op1 = {0}, oper = {0}, op2 = {0};

	switch(ppc->lookahead.op) {
		case TOKEN_STRING:
			op1 = ppc->lookahead;	/* save first operand (kw or tagname) */
			get_new_token(ppc);
			if(
				ppc->lookahead.op == TOKEN_LT ||
				ppc->lookahead.op == TOKEN_LE ||
				ppc->lookahead.op == TOKEN_GT ||
				ppc->lookahead.op == TOKEN_GE ||
				ppc->lookahead.op == TOKEN_EQ ||
				ppc->lookahead.op == TOKEN_NE
			  ) {
				op1 = specialtagname(op1);	/* perform translation */
				oper = ppc->lookahead;	/* save operator */
				if(oper.op == TOKEN_LT || oper.op == TOKEN_LE ||
				   oper.op == TOKEN_GT || oper.op == TOKEN_GE) {
					if(op1.op == TOKEN_STRING)
						op1.op = TOKEN_TAGDWORDNAME;
					else if(op1.op == TOKEN_TAGSTRINGNAME)
						parse_error(ppc, PARSING_INVALID_STRING_TAGNAME, "Special tagname has string values, can't be followed by ", oper.s);
				} else if(op1.op == TOKEN_STRING) { /* if == or != */
						/* unless changed to TOKEN_TAGDWORDNAME by specialtagname() */
						op1.op = TOKEN_TAGSTRINGNAME;
				}
				emit(ppc, &op1);	/* ### code generation: tagname */
				get_new_token(ppc);	/* get tagvalue */

				if (ppc->lookahead.op == TOKEN_STRING) {
					op2 = ppc->lookahead;
					get_new_token(ppc);
					if(op1.op == TOKEN_TAGDWORDNAME) {
						/* embed value in operator's token */
						char *endstr;
						oper.limit = strtoul(op2.s, &endstr, 0);
						if(endstr != op2.s + op2.length) {
							parse_error(ppc, PARSING_EXPECTED_NUMERIC_OPERAND, "Non-numeric operand after <, <=, >, >=: ", op2.s);
							return;
						}
					} else {	/* String operand: always treat operand as string */
						/* emit a separate code for the tagvalue */
						op2.op = TOKEN_TAGSTRINGVALUE;
						emit(ppc, &op2);	/* ### code generation: tagvalue */
					}
				} else {
					parse_error(ppc, PARSING_MISSING_STRING_OPERAND, "Missing string operand: ", ppc->lookahead.s);
					return;
				}

				/* See if we had a == or != with numeric operand. If so,
				   op1 was emitted, and oper embeds the value of op2.
				   Then, expand "=(op2)" into ">=(op2) op1 <=(op2) &"  and
				   "!=(op2)" into ">(op2) op1 <(op2) |" */
				if(oper.op == TOKEN_EQ && op1.op == TOKEN_TAGDWORDNAME) {
					token tand =    {"&",  TOKEN_AND, 1, 0};
					token relop = oper;
					if(oper.limit == 0) {
						/* == 0 is just <= 0 */
						relop.op = TOKEN_LE;
						relop.s = "<=";
						emit(ppc, &relop);	/* op2's value is embedded... */
					} else if(oper.limit == 0xffffffff) {
						/* == 0xffffffff is just >= 0xffffffff */
						relop.op = TOKEN_GE;
						relop.s = ">=";
						emit(ppc, &relop);	/* op2's value is embedded... */
					} else {
						relop.op = TOKEN_LE;
						relop.s = "<=";
						emit(ppc, &relop);	/* op2's value is embedded... */

						emit(ppc, &op1);

						relop.op = TOKEN_GE;
						relop.s = ">=";
						emit(ppc, &relop);	/* op2's value is embedded... */

						emit(ppc, &tand);
					}
				} else if(oper.op == TOKEN_NE && op1.op == TOKEN_TAGDWORDNAME) {
					token tor =    {"|",  TOKEN_OR, 1, 0};
					token relop = oper;
					if(oper.limit == 0) {
						/* != 0 is just > 0 */
						relop.op = TOKEN_GT;
						relop.s = ">";
						emit(ppc, &relop);	/* op2's value is embedded... */
					} else if(oper.limit == 0xffffffff) {
						/* != 0xffffffff is just < 0xffffffff */
						relop.op = TOKEN_LT;
						relop.s = "<";
						emit(ppc, &relop);	/* op2's value is embedded... */
					} else {
						relop.op = TOKEN_LT;
						relop.s = "<";
						emit(ppc, &relop);	/* op2's value is embedded... */

						emit(ppc, &op1);

						relop.op = TOKEN_GT;
						relop.s = ">";
						emit(ppc, &relop);	/* op2's value is embedded... */

						emit(ppc, &tor);
					}
				} else {	/* no expansion needed */
					emit(ppc, &oper);	/* ### code generation: operator */
				}
			} else {
				/* keyword, not first operand of a relop */
				if(op1.length == 0)
					op1.op = TOKEN_TRUE;	/* zero-length keyww are semantically TRUE */
				else
					op1.op = TOKEN_KEYWORD;
				emit(ppc, &op1);	/* ### code generation: kw or .TRUE. */
			}
			break;
		case TOKEN_NOT:
			oper = ppc->lookahead;
			get_new_token(ppc);
			if(ppc->lookahead.op == TOKEN_NOT) {	/* optimization: omit NOT NOT */
				get_new_token(ppc); /* eat the coming NOT and do not emit code for this one */
				predicate(ppc);
			} else {
				predicate(ppc);
				emit(ppc, &oper);	/* ### code generation: NOT operator */
			}
			break;
		case TOKEN_LPAR:
			get_new_token(ppc);
			expr(ppc);
			if (ppc->lookahead.op != TOKEN_RPAR) {
				parse_error(ppc, PARSING_MISSING_RIGHT_PAREN, "Missing ')': ", ppc->lookahead.s);
				return;
			}
			get_new_token(ppc);
			break;
		default:
			parse_error(ppc, PARSING_EXPECTED_RELEX_OR_PAREN_BOOLEX, "Expected relational expression or (boolean expression): ", ppc->lookahead.s);
			return;
	}
}

static void term(parsercontext *ppc) {
	predicate(ppc);
	while (ppc->lookahead.op == TOKEN_AND) {
		token t = ppc->lookahead;
		get_new_token(ppc);
		predicate(ppc);
		emit(ppc, &t);	/* ### code generation */
	}
}

static void expr(parsercontext *ppc) {
	term(ppc);
	while (ppc->lookahead.op == TOKEN_OR) {
		token t = ppc->lookahead;
		get_new_token(ppc);
		term(ppc);
		emit(ppc, &t);	/* ### code generation */
	}
}

KadC_parsedfilter KadC_parsefilter(char *stringex) {
	parsercontext pc = {0};
	int stringexlen = 0;
	KadC_parsedfilter pf = {0};

	pf.err = 0;
	pf.errmsg1 = pf.errmsg2 = "";
	if(stringex == NULL || (stringexlen = strlen(stringex)) == 0) {
		/* a NULL or empty stringex is not an error */
		pf.nsf = malloc(2);
		pf.nsf[0] = pf.nsf[1] = 0;	/* but the nsfilter has zero length */
		return pf;
	}
	pc.p = stringex;
	pc.pend = stringex+strlen(stringex);
	pc.tsp = 0;
	pc.tssize = 3*stringexlen;		/* at most, 3-char relops like SIZE=1 may expand to 7 tokens */
	pc.tstack = malloc(pc.tssize * sizeof(*pc.tstack));	/* allocate intermediate code stack */
	if(pc.tstack == NULL) {
		pf.err = PARSING_OUT_OF_MEMORY;
		pf.errmsg1 = "Out of memory: NULL returned by malloc()";
		pf.errmsg2 = "";
		return pf;
	}
	pc.errcode = PARSING_OK;		/* default */

	get_new_token(&pc);				/* prime the lookahead token */
	expr(&pc);						/* do the recursive parsing - PASS 1 */

	if(pc.lookahead.op == TOKEN_ERR) {
		pc.errcode = PARSING_LEXICAL_ERROR;
		pc.err1	= "Lexical error before: ";
		pc.err2	= pc.lookahead.s;
	} else if (pc.lookahead.op != TOKEN_EOF) {
		pc.errcode = PARSING_EXTRA_GARBAGE;
		pc.err1 = "Expression is followed by extra garbage: ";
		pc.err2 = pc.lookahead.s;
	}

#ifdef DEBUG
	printf("\n");
#endif

	/* PASS 2: from intermediate opcode to actual filter */

	if(pc.errcode != 0) {
		int i;
		for(i=0; i<pc.tsp; i++)
			free(pc.tstack[i]);	/* clean up stack freeing tokens on it */

		pf.err = pc.errcode;
		pf.errmsg1 = pc.err1;
		pf.errmsg2 = pc.err2;
	} else {
		/* now pc.tstack contains pc.tsp tokens in RPN: let's generate the filter (pass 2) */
		/* alloc a filter buffer in pf.nsf */
		pf.nsf = malloc(MAXFILTERSIZE);
		if(pf.nsf == 0) {
			pf.err = PARSING_OUT_OF_MEMORY;
			pf.errmsg1 = "Out of memory: NULL returned by malloc()";
			pf.errmsg2 = "";
		} else {
			int i;
			unsigned char *p = pf.nsf+2;

			pf.nsf[0] = pf.nsf[1] = 0;	/* the nsfilter has zero length for now */
			/* reverse the stack into pf.nsf */
			for(i=pc.tsp - 1; i >= 0; i--) {
			  if(pf.err == PARSING_OK)
				switch(pc.tstack[i]->op) {
				case TOKEN_AND:
					*(p++) = EDONKEY_SEARCH_BOOL;	/* 0x00 */
					*(p++) = EDONKEY_SEARCH_AND;	/* 0x00 */
					break;
				case TOKEN_OR:
					*(p++) = EDONKEY_SEARCH_BOOL;	/* 0x00 */
					*(p++) = EDONKEY_SEARCH_OR;		/* 0x01 */
					break;
				case TOKEN_AND_NOT:
					*(p++) = EDONKEY_SEARCH_BOOL;	/* 0x00 */
					*(p++) = EDONKEY_SEARCH_ANDNOT;	/* 0x02 */
					break;
				case TOKEN_GT:
					*(p++) = EDONKEY_SEARCH_LIMIT;	/* 0x03 */
					putulongle(&p, pc.tstack[i]->limit);
					*(p++) = EDONKEY_SEARCH_MIN;	/* 0x01 */
					break;
				case TOKEN_LT:
					*(p++) = EDONKEY_SEARCH_LIMIT;	/* 0x03 */
					putulongle(&p, pc.tstack[i]->limit);
					*(p++) = EDONKEY_SEARCH_MAX;	/* 0x02 */
					break;
				case TOKEN_EQ:
					*(p++) = EDONKEY_SEARCH_META;
					break;
				case TOKEN_KEYWORD:
					*(p++) = EDONKEY_SEARCH_NAME;
					putushortle(&p, pc.tstack[i]->length);
					memcpy(p, pc.tstack[i]->s, pc.tstack[i]->length);
					p += pc.tstack[i]->length;
					break;
				case TOKEN_TRUE:	/* only used as special keyword */
					*(p++) = EDONKEY_SEARCH_NAME;
					*(p++) = 0;
					*(p++) = 0;
					break;
				case TOKEN_TAGSTRINGNAME:
				case TOKEN_TAGDWORDNAME:
				case TOKEN_TAGSTRINGVALUE:
					putushortle(&p, pc.tstack[i]->length);
					memcpy(p, pc.tstack[i]->s, pc.tstack[i]->length);
					if(pc.tstack[i]->op != TOKEN_TAGSTRINGVALUE &&
						pc.tstack[i]->length > 1) {
						/* force non-special tagnames to lowercase */
						int j;
						for(j=0; j<pc.tstack[i]->length; j++)
							p[j]=tolower(p[j]);
					}
					p += pc.tstack[i]->length;
					break;
				default:
					pf.err = PARSING_UNKNOWN_OPCODE_IN_PASS_2;
					pf.errmsg1 = "Unknown intermediate opcode: ";
					pf.errmsg2 = pc.tstack[i]->s;
				}
				free(pc.tstack[i]);
			}
			/* adjust the first two bytes of pf.nsf (as nstring) */
			i = p - (pf.nsf+2);
			p = pf.nsf;
			putushortle(&p, i);
			/* resize the buffer with realloc() */
			pf.nsf = realloc(pf.nsf, i+2);
		}
	}
	free(pc.tstack);
	return pf;	/* temp: actually, return ns_filter */
}

